---
created_at: 2011-05-18
excerpt: Esiste un modo di minimizzare il numero di falsi positivi durante la ricerca di cross site scripting? Proviamoci.
kind: article
publish: true
lang: [it]
tags: [appsec, application security, owasp, owasp top 10, ruby, mechanize, nokogiri, cross, project, xss, cross site scripting]
title: "Mechanize+Nokogiri = Cross"
place: Gessate
---

%p
  I
  %a{:href=>'https://www.owasp.org/index.php/Cross-site_Scripting_(XSS)'}
    Cross site scripting
  sono la famiglia di vulnerabilità più diffusa tra quelli che affliggono le
  web application.
  %br
  Paradossalmente è tra i più diffusi ma anche tra i più semplici da eliminare.
  Un mantra della programmazione difensiva vuole che non si debba mai prendere
  come
  %em
    trusted
  qualsiasi dato proveniente dall'esterno (form HTML, parametri della query
  string o della sessione, ...).
%p
  Molti sviluppatori non considerano questo rischio, prendono in pancia un
  input e lo visualizzano successivamente senza modifiche. A meno di non
  utilizzare framework come 
  %a{:href=>'http://ruyonrails.org'}
    Rails
  che fanno il lavoro sporco per noi, l'attaccante potrà iniettare codice
  javascript arbitrario nelle pagine dell'applicazione.
%p
  I tool di penetration test simulano l'operato dell'attaccante e cercano nella
  pagina in output la string appena iniettata. 
  %br
  Mi è capitato, soprattutto coi tool commerciali che il pattern fosse si
  presente ma in commenti o inserito all'interno dell'html in modo tale da
  renderlo inoffensivo in quanto non interpretato dal browser.
%p
  Come giochino della domenica sto provando a giocare con 
  %a{:href=>'http://mechanize.rubyforge.org/mechanize'}
    mechanize
  e 
  %a{:href=>'http://nokogiri.org/'}
    nokogiri.
%p
  Mechanize è una gemma che permette l'interazione di uno script ruby con le
  pagine web, permette di popolare form, seguire i link e premere pulsanti.
  %br
  Nokogiri è invece un parser per HTML, XML e SAX e può venire utile nel fare
  parsing della pagina restituita dalla web application.
%p
  A dire la verità mi era venuta in mente guardando
  %a{:href=>'http://watir.com'}
    watir
  e facendo TDD sui miei controller usando rspec e capybara.
%p
  Ho fatto partire un progettino della domenica, senza nessuna pretesa e l'ho
  chiamato 
  %a{:href=>'https://github.com/thesp0nge/cross'}
    cross
%p
  L'idea è semplice, partendo da una URL andare a recuperare la sitemap e se
  non presente andare a fare un crawling del sito per usare mechanize sulle
  form, sulle query string, sui parametri di sessione e vedere se i pattern che
  sono stati inseriti sono in posizioni del DOM che possono essere inrepretate
  dal browser come codice da eseguire.
%p
  Sinceramente non so quanto tempo ci dedicherò, però potrebbe essere
  interessante creare anche dei rake task che possano integrarsi in un progetto
  rails ad esempio in modo da lanciare la ricerca di XSS all'interno
  dell'esecuzione del nostro ciclo di TDD.

